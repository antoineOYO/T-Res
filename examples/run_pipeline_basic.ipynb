{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic T-Res pipeline\n",
    "\n",
    "An example of how to run the basic pipeline (with default values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from t_res.geoparser import pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `pipeline` script has been imported (in the previous cell), we create a new object of the `Pipeline` class. Since we don't pass any parameters, it will take all the default values: it will detect toponyms using `Livingwithmachines/toponym-19thC-en` NER model, it will find candidates using the perfect match approach, and will disambiguate them using the most popular approach. You can see the default `Pipeline` values [here](https://living-with-machines.github.io/T-Res/reference/geoparser/pipeline.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating and loading a NER pipeline.\n",
      "*** Loading the ranker resources.\n",
      "*** Load linking resources.\n",
      "  > Loading mentions to wikidata mapping.\n",
      "  > Loading gazetteer.\n",
      "*** Linking resources loaded!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "geoparser = pipeline.Pipeline(resources_path=\"../resources/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the pipeline: end-to-end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline can take either a sentence (`run_sentence`) or a document (`run_text`). If the latter, the text is split into sentences using the `sentence-splitter` library. See an example of how to run each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mention': 'Valence',\n",
       "  'ner_score': 1.0,\n",
       "  'pos': 12,\n",
       "  'sent_idx': 0,\n",
       "  'end_pos': 19,\n",
       "  'tag': 'LOC',\n",
       "  'sentence': 'The city of Valence.',\n",
       "  'prediction': 'Q8848',\n",
       "  'ed_score': 0.876,\n",
       "  'string_match_score': {'Valence': (1.0,\n",
       "    ['Q8818',\n",
       "     'Q2875976',\n",
       "     'Q8848',\n",
       "     'Q2052261',\n",
       "     'Q1467944',\n",
       "     'Q1361868',\n",
       "     'Q3097931',\n",
       "     'Q702697',\n",
       "     'Q495485'])},\n",
       "  'prior_cand_score': {},\n",
       "  'cross_cand_score': {'Q8848': 0.876,\n",
       "   'Q1467944': 0.053,\n",
       "   'Q1361868': 0.046,\n",
       "   'Q702697': 0.007,\n",
       "   'Q2052261': 0.005,\n",
       "   'Q3097931': 0.005,\n",
       "   'Q8818': 0.002},\n",
       "  'latlon': [44.9325, 4.890833],\n",
       "  'wkdt_class': 'Q484170'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolved = geoparser.run_text(\" The city of Valence.\")\n",
    "resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'mention': 'Sheffield', 'ner_score': 1.0, 'pos': 74, 'sent_idx': 0, 'end_pos': 83, 'tag': 'LOC', 'sentence': 'A remarkable case of rattening has just occurred in the building trade at Sheffield.', 'prediction': 'Q42448', 'ed_score': 0.896, 'string_match_score': {'Sheffield': (1.0, ['Q6707254', 'Q823917', 'Q5953687', 'Q7492778', 'Q1421317', 'Q7492594', 'Q897533', 'Q42448', 'Q7492565', 'Q1862179', 'Q4834926', 'Q17643392', 'Q7492570', 'Q1950928', 'Q2277715', 'Q79568', 'Q518864', 'Q7492591', 'Q2306176', 'Q7492775', 'Q741640', 'Q7492686', 'Q3577611', 'Q12956644', 'Q547824', 'Q7684835', 'Q3365926', 'Q7492719', 'Q7492566', 'Q7492567', 'Q4523493', 'Q3028626', 'Q7492607', 'Q7492568', 'Q1984238', 'Q1184547', 'Q925542', 'Q4664093', 'Q2892594', 'Q1916592', 'Q371969', 'Q1141915', 'Q6986914', 'Q7114883', 'Q1915446', 'Q5224096', 'Q7492766', 'Q15277074', 'Q4065168', 'Q1548891', 'Q7492772', 'Q977409', 'Q1752117', 'Q7492586', 'Q5035049', 'Q108940076'])}, 'prior_cand_score': {}, 'cross_cand_score': {'Q42448': 0.896, 'Q1862179': 0.025, 'Q823917': 0.013, 'Q2306176': 0.008, 'Q2277715': 0.006, 'Q79568': 0.005, 'Q7492778': 0.003}, 'latlon': [53.380833, -1.470278], 'wkdt_class': 'Q515'}]\n"
     ]
    }
   ],
   "source": [
    "resolved = geoparser.run_sentence(\"A remarkable case of rattening has just occurred in the building trade at Sheffield.\")\n",
    "print(resolved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the pipeline: step-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the end-to-end pipeline, the pipeline can be used step-wise.\n",
    "\n",
    "Therefore, it can be used to just perform toponym recognition (i.e. NER):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'mention': 'Sheffield', 'context': ['', ''], 'candidates': [], 'gold': ['NONE'], 'ner_score': 1.0, 'pos': 74, 'sent_idx': 0, 'end_pos': 83, 'ngram': 'Sheffield', 'conf_md': 1.0, 'tag': 'LOC', 'sentence': 'A remarkable case of rattening has just occurred in the building trade at Sheffield.', 'place': '', 'place_wqid': ''}]\n"
     ]
    }
   ],
   "source": [
    "mentions = geoparser.run_text_recognition(\"A remarkable case of rattening has just occurred in the building trade at Sheffield.\")\n",
    "print(mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline can then be used to just perform candidate selection given the output of NER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sheffield': {'Sheffield': {'Score': 1.0, 'Candidates': {'Q6707254': 0.038461538461538464, 'Q823917': 0.04389027431421446, 'Q5953687': 0.25, 'Q7492778': 0.21153846153846156, 'Q1421317': 0.044117647058823525, 'Q7492594': 0.05, 'Q897533': 0.026007802340702213, 'Q42448': 0.9632482747552559, 'Q7492565': 0.7058823529411764, 'Q1862179': 0.6057347670250897, 'Q4834926': 0.043478260869565216, 'Q17643392': 0.047619047619047616, 'Q7492570': 0.7391304347826086, 'Q1950928': 0.6666666666666666, 'Q2277715': 0.7636363636363636, 'Q79568': 0.2857142857142857, 'Q518864': 0.6551724137931034, 'Q7492591': 0.20454545454545456, 'Q2306176': 0.3943661971830986, 'Q7492775': 0.125, 'Q741640': 0.16666666666666666, 'Q7492686': 0.25, 'Q3577611': 0.1, 'Q12956644': 0.22988505747126436, 'Q547824': 0.09090909090909091, 'Q7684835': 0.1, 'Q3365926': 0.47058823529411764, 'Q7492719': 0.125, 'Q7492566': 0.6071428571428571, 'Q7492567': 1.0, 'Q4523493': 0.07692307692307693, 'Q3028626': 0.07792207792207792, 'Q7492607': 0.007142857142857143, 'Q7492568': 1.0, 'Q1984238': 0.4482758620689655, 'Q1184547': 0.6818181818181819, 'Q925542': 0.2, 'Q4664093': 0.09523809523809523, 'Q2892594': 0.015151515151515152, 'Q1916592': 0.6666666666666666, 'Q371969': 0.058823529411764705, 'Q1141915': 0.0035842293906810036, 'Q6986914': 0.14285714285714285, 'Q7114883': 0.12631578947368421, 'Q1915446': 0.011363636363636364, 'Q5224096': 0.0625, 'Q7492766': 0.08333333333333333, 'Q15277074': 0.36666666666666664, 'Q4065168': 0.007518796992481203, 'Q1548891': 0.011049723756906077, 'Q7492772': 0.1111111111111111, 'Q977409': 0.07142857142857142, 'Q1752117': 0.004123711340206186, 'Q7492586': 0.08333333333333333, 'Q5035049': 0.043478260869565216, 'Q108940076': 0.75}}}}\n"
     ]
    }
   ],
   "source": [
    "candidates = geoparser.run_candidate_selection(mentions)\n",
    "print(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, the pipeline can be used to perform entity disambiguation, given the output from the previous two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'mention': 'Sheffield', 'ner_score': 1.0, 'pos': 74, 'sent_idx': 0, 'end_pos': 83, 'tag': 'LOC', 'sentence': 'A remarkable case of rattening has just occurred in the building trade at Sheffield.', 'prediction': 'Q42448', 'ed_score': 0.896, 'string_match_score': {'Sheffield': (1.0, ['Q6707254', 'Q823917', 'Q5953687', 'Q7492778', 'Q1421317', 'Q7492594', 'Q897533', 'Q42448', 'Q7492565', 'Q1862179', 'Q4834926', 'Q17643392', 'Q7492570', 'Q1950928', 'Q2277715', 'Q79568', 'Q518864', 'Q7492591', 'Q2306176', 'Q7492775', 'Q741640', 'Q7492686', 'Q3577611', 'Q12956644', 'Q547824', 'Q7684835', 'Q3365926', 'Q7492719', 'Q7492566', 'Q7492567', 'Q4523493', 'Q3028626', 'Q7492607', 'Q7492568', 'Q1984238', 'Q1184547', 'Q925542', 'Q4664093', 'Q2892594', 'Q1916592', 'Q371969', 'Q1141915', 'Q6986914', 'Q7114883', 'Q1915446', 'Q5224096', 'Q7492766', 'Q15277074', 'Q4065168', 'Q1548891', 'Q7492772', 'Q977409', 'Q1752117', 'Q7492586', 'Q5035049', 'Q108940076'])}, 'prior_cand_score': {}, 'cross_cand_score': {'Q42448': 0.896, 'Q1862179': 0.025, 'Q823917': 0.013, 'Q2306176': 0.008, 'Q2277715': 0.006, 'Q79568': 0.005, 'Q7492778': 0.003}, 'latlon': [53.380833, -1.470278], 'wkdt_class': 'Q515'}]\n"
     ]
    }
   ],
   "source": [
    "disamb_output = geoparser.run_disambiguation(mentions, candidates)\n",
    "print(disamb_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from t_res.geoparser import pipeline, ranking, linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# Instantiate the ranker:\n",
    "myranker = ranking.Ranker(\n",
    "    method=\"deezymatch\",\n",
    "    resources_path=\"../resources/\",\n",
    "    strvar_parameters={\n",
    "        # Parameters to create the string pair dataset:\n",
    "        \"ocr_threshold\": 60,\n",
    "        \"top_threshold\": 85,\n",
    "        \"min_len\": 5,\n",
    "        \"max_len\": 15,\n",
    "        \"w2v_ocr_path\": str(Path(\"../resources/models/w2v/\").resolve()),\n",
    "        \"w2v_ocr_model\": \"w2v_*_news\",\n",
    "        \"overwrite_dataset\": False,\n",
    "    },\n",
    "    deezy_parameters={\n",
    "        # Paths and filenames of DeezyMatch models and data:\n",
    "        \"dm_path\": str(Path(\"../resources/deezymatch/\").resolve()),\n",
    "        \"dm_cands\": \"wkdtalts\",\n",
    "        \"dm_model\": \"w2v_ocr\",\n",
    "        \"dm_output\": \"deezymatch_on_the_fly\",\n",
    "        # Ranking measures:\n",
    "        \"ranking_metric\": \"faiss\",\n",
    "        \"selection_threshold\": 50,\n",
    "        \"num_candidates\": 1,\n",
    "        \"verbose\": False,\n",
    "        # DeezyMatch training:\n",
    "        \"overwrite_training\": False,\n",
    "        \"do_test\": False,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Valence, (Géograph. mod.) petite ville, disons mieux, bourg de France dans l'Agénois, sur la rive droite de la Garonne, vis-à-vis d'Aurignac. (D. J.) \n",
    "\n",
    "    LOURDE, Laperdum, (Géog.) petite ville de France en Gascogne, ville unique, & chef-lieu du Lavedan, avec un ancien château sur un rocher. Elle est sur le Gave de Pau, à 4 lieues de Bagnieres. Long. 17. 30. lat. 43. 8. (D. J.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmyranker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmentions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mValence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFrance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAgénois\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGaronne\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAurignac\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/T-Res/t_res/geoparser/ranking.py:686\u001b[0m, in \u001b[0;36mRanker.find_candidates\u001b[0;34m(self, mentions)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;124;03mFind candidates for the given mentions using the selected ranking\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03mmethod.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m    attribute).\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;66;03m# Extract the mention\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m([mention[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmention\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m mention \u001b[38;5;129;01min\u001b[39;00m mentions]))\n\u001b[1;32m    688\u001b[0m \u001b[38;5;66;03m# Pass the mentions to :py:meth:`geoparser.ranking.Ranker.run`\u001b[39;00m\n\u001b[1;32m    689\u001b[0m cands, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malready_collected_cands \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(queries)\n",
      "File \u001b[0;32m~/Documents/GitHub/T-Res/t_res/geoparser/ranking.py:686\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;124;03mFind candidates for the given mentions using the selected ranking\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03mmethod.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m    attribute).\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;66;03m# Extract the mention\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[43mmention\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m mention \u001b[38;5;129;01min\u001b[39;00m mentions]))\n\u001b[1;32m    688\u001b[0m \u001b[38;5;66;03m# Pass the mentions to :py:meth:`geoparser.ranking.Ranker.run`\u001b[39;00m\n\u001b[1;32m    689\u001b[0m cands, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malready_collected_cands \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(queries)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "myranker.find_candidates(mentions = ['Valence', 'France', 'Agénois', 'Garonne', 'Aurignac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tres-turing",
   "language": "python",
   "name": "tres-turing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
