{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and using a NER model\n",
    "\n",
    "This notebook shows how to load an existing named entity recognition (NER) model from the HuggingFace hub, using T-Res.\n",
    "\n",
    "We start by importing some libraries, and the `recogniser` script from the `geoparser` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cu121\n",
      "4.39.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from t_res.geoparser import recogniser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `myner` object of the `Recogniser` class.\n",
    "\n",
    "We only need to pass the path to the model in `model` and set `load_from_hub` to True, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "myner = recogniser.Recogniser(\n",
    "    model=\"Livingwithmachines/toponym-19thC-en\",\n",
    "    load_from_hub=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the Recogniser (see that most fields are empty, because they are not needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Toponym recogniser:\n",
      "    * Model path: \n",
      "    * Model name: Livingwithmachines/toponym-19thC-en\n",
      "    * Base model: \n",
      "    * Overwrite model if exists: False\n",
      "    * Train in test mode: False\n",
      "    * Load from hub: True\n",
      "    * Training args: {'batch_size': 8, 'num_train_epochs': 10, 'learning_rate': 5e-05, 'weight_decay': 0.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(myner)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to train the model, nothing happens, because we're loading an existing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmyner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mner_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe river Thames flows through London.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m :\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB-LOC\u001b[39m\u001b[38;5;124m\"\u001b[39m :\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(token[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m] )  \n",
      "File \u001b[0;32m~/Documents/GitHub/T-Res/t_res/geoparser/recogniser.py:380\u001b[0m, in \u001b[0;36mRecogniser.ner_predict\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    377\u001b[0m sentence \u001b[38;5;241m=\u001b[39m sentence[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m sentence[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâ€”\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# Run the NER pipeline to predict mentions:\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m ner_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# Post-process the predictions, fixing potential grouping errors:\u001b[39;00m\n\u001b[1;32m    383\u001b[0m lEntities \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "for token in myner.ner_predict(\"The river Thames flows through London.\") :\n",
    "    if token['entity'] == \"B-LOC\" :\n",
    "        print(token['word'] )  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to use the model you want to use, you'll need to load it into a NER pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating and loading a NER pipeline.\n"
     ]
    }
   ],
   "source": [
    "myner.pipe = myner.create_pipeline()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, use the newly trained model to predict the named entities in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'O',\n",
       "  'score': 0.9999761581420898,\n",
       "  'word': 'A',\n",
       "  'start': 0,\n",
       "  'end': 1},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9999762773513794,\n",
       "  'word': 'remarkable',\n",
       "  'start': 2,\n",
       "  'end': 12},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9999761581420898,\n",
       "  'word': 'case',\n",
       "  'start': 13,\n",
       "  'end': 17},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9999761581420898,\n",
       "  'word': 'of',\n",
       "  'start': 18,\n",
       "  'end': 20},\n",
       " {'entity': 'O',\n",
       "  'score': 0.999976396560669,\n",
       "  'word': 'rattening',\n",
       "  'start': 21,\n",
       "  'end': 30},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9999761581420898,\n",
       "  'word': 'has',\n",
       "  'start': 31,\n",
       "  'end': 34},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9999762773513794,\n",
       "  'word': 'just',\n",
       "  'start': 35,\n",
       "  'end': 39},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9999762773513794,\n",
       "  'word': 'occurred',\n",
       "  'start': 40,\n",
       "  'end': 48},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9999761581420898,\n",
       "  'word': 'in',\n",
       "  'start': 49,\n",
       "  'end': 51},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9999761581420898,\n",
       "  'word': 'the',\n",
       "  'start': 52,\n",
       "  'end': 55},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9999755620956421,\n",
       "  'word': 'building',\n",
       "  'start': 56,\n",
       "  'end': 64},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9999756813049316,\n",
       "  'word': 'trade',\n",
       "  'start': 65,\n",
       "  'end': 70},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9999756813049316,\n",
       "  'word': 'at',\n",
       "  'start': 71,\n",
       "  'end': 73},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.9996446371078491,\n",
       "  'word': 'Sheffield',\n",
       "  'start': 74,\n",
       "  'end': 83},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9999758005142212,\n",
       "  'word': '.',\n",
       "  'start': 83,\n",
       "  'end': 84}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"A remarkable case of rattening has just occurred in the building trade at Sheffield.\"\n",
    "\n",
    "predictions = myner.ner_predict(sentence)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tres-turing",
   "language": "python",
   "name": "tres-turing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
